<!doctype html><html lang=zh><head><meta name=viewport content="width=device-width,initial-scale=1"><title>利用互联网检索优化RAG模型的时效性问题</title>
<meta charset=utf-8><meta name=google-adsense-account content="ca-pub-2871082647721658"><meta content="Web开发 ,Java ,Go ,Node.js ,PHP ,Koa ,MySQL ,Redis ,前端 ,后端 ,数据库" name=keywords><meta name=description content="在当今信息爆炸的时代，我们每天都在生成和消费海量的数据。对于依赖大量最新数据进行决策的领域，如金融分析、市场研究或实时新闻报道，传统的机器学习模型可能难以满足需求，因为它们通常在训练后便固定下来，难以适应快速变化的信息环境。近年来，Retrieval-Augmented Generation（RAG）模型因其结合了检索和生成的能力而受到关注。然而，RAG模型也面临着时效性问题。本文将探讨如何通过互联网检索和大型语言模型（LLM）来优化RAG模型的时效性。"><meta name=author content="Lei Xia"><link rel=canonical href=https://www.ddhigh.com/2024/06/26/rag-with-internet/><link rel=alternate type=application/rss+xml href=https://www.ddhigh.com//index.xml title=每天进步一点点><script async defer data-website-id=52f8f0f9-d93d-466b-8ef5-508aae8c4ed4 src=https://analysis.ddhigh.com/script.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-EC3XLVSGKV"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-EC3XLVSGKV")</script><meta property="og:url" content="https://www.ddhigh.com/2024/06/26/rag-with-internet/"><meta property="og:site_name" content="每天进步一点点"><meta property="og:title" content="利用互联网检索优化RAG模型的时效性问题"><meta property="og:description" content="在当今信息爆炸的时代，我们每天都在生成和消费海量的数据。对于依赖大量最新数据进行决策的领域，如金融分析、市场研究或实时新闻报道，传统的机器学习模型可能难以满足需求，因为它们通常在训练后便固定下来，难以适应快速变化的信息环境。近年来，Retrieval-Augmented Generation（RAG）模型因其结合了检索和生成的能力而受到关注。然而，RAG模型也面临着时效性问题。本文将探讨如何通过互联网检索和大型语言模型（LLM）来优化RAG模型的时效性。"><meta property="og:locale" content="zh"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-06-26T12:30:57+08:00"><meta property="article:modified_time" content="2024-06-26T12:30:57+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="利用互联网检索优化RAG模型的时效性问题"><meta name=twitter:description content="在当今信息爆炸的时代，我们每天都在生成和消费海量的数据。对于依赖大量最新数据进行决策的领域，如金融分析、市场研究或实时新闻报道，传统的机器学习模型可能难以满足需求，因为它们通常在训练后便固定下来，难以适应快速变化的信息环境。近年来，Retrieval-Augmented Generation（RAG）模型因其结合了检索和生成的能力而受到关注。然而，RAG模型也面临着时效性问题。本文将探讨如何通过互联网检索和大型语言模型（LLM）来优化RAG模型的时效性。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://www.ddhigh.com/posts/"},{"@type":"ListItem","position":2,"name":"利用互联网检索优化RAG模型的时效性问题","item":"https://www.ddhigh.com/2024/06/26/rag-with-internet/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"利用互联网检索优化RAG模型的时效性问题","name":"利用互联网检索优化RAG模型的时效性问题","description":"在当今信息爆炸的时代，我们每天都在生成和消费海量的数据。对于依赖大量最新数据进行决策的领域，如金融分析、市场研究或实时新闻报道，传统的机器学习模型可能难以满足需求，因为它们通常在训练后便固定下来，难以适应快速变化的信息环境。近年来，Retrieval-Augmented Generation（RAG）模型因其结合了检索和生成的能力而受到关注。然而，RAG模型也面临着时效性问题。本文将探讨如何通过互联网检索和大型语言模型（LLM）来优化RAG模型的时效性。\n","keywords":[],"articleBody":"在当今信息爆炸的时代，我们每天都在生成和消费海量的数据。对于依赖大量最新数据进行决策的领域，如金融分析、市场研究或实时新闻报道，传统的机器学习模型可能难以满足需求，因为它们通常在训练后便固定下来，难以适应快速变化的信息环境。近年来，Retrieval-Augmented Generation（RAG）模型因其结合了检索和生成的能力而受到关注。然而，RAG模型也面临着时效性问题。本文将探讨如何通过互联网检索和大型语言模型（LLM）来优化RAG模型的时效性。\nRAG模型及其时效性挑战 RAG模型通过将检索组件与生成组件相结合，提高了模型对特定查询的响应能力。然而，如果模型仅依赖于预先训练好的数据，它可能无法提供最新的信息。例如，在体育赛事中，比赛结束后，人们期望模型能够提供最新的比分和统计数据，而不是过时的信息。\n为了解决时效性问题，我们可以利用互联网搜索引擎作为数据源。搜索引擎能够索引最新的网页内容，为我们提供实时更新的数据。通过编写特定的爬虫或使用API，我们可以从搜索引擎获取与查询相关的最新网页内容。\n获取到最新的语料后，我们可以将其输入到大型语言模型中进行内容生成。LLM的强大之处在于它们能够理解和生成自然语言，这使得它们成为生成连贯、准确和相关文本的理想选择。\n基于搜索引擎的RAG例子 接下来笔者将以一个基于百度搜索引擎以及月之暗面大模型的RAG例子进行逐步示范：\n安装组件 pip install requests pip install bs4 pip install langchain_openai pip install langchain_core 构建检索器 检索器需要继承langchain_core.runnables.Runnable并实现invoke方法，因此我们可以以任意数据源来构建检索器，而不仅仅是搜索引擎，下面是基于百度搜索引擎查询关键字并提取文本的代码：\nclass CustomWebSearchRetriever(Runnable): def __init__(self, search_url, headers=None): self.search_url = search_url self.headers = headers or {} def retrieve(self, query): response = requests.get(self.search_url, headers=self.headers, params={'wd': query}) soup = BeautifulSoup(response.text, 'html.parser') search_results = soup.find_all('div', class_='result') print(f\"searched {len(search_results)} results\") return '\\n'.join([result.get_text() for result in search_results]) def invoke(self, input: Input, config: Optional[RunnableConfig] = None) -\u003e Output: # invoke方法调用retrieve方法，并返回结果 print('querying', str(input)) return self.retrieve(input) 初始化LLM 笔者使用的是月之暗面，在前面的内容中我提到过Langchain提供了非常多的LLM，比如OpenAI的ChatGPT以及开源的llama3等。\nllm = ChatOpenAI( model_name='moonshot-v1-8k', temperature=0.75, openai_api_base='https://api.moonshot.cn/v1', openai_api_key='秘钥', streaming=False, ) 初始化检索器 # 配置搜索引擎的URL和headers search_url = \"https://www.baidu.com/s\" # 这里需要替换为实际的搜索引擎URL headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3' } # 初始化自定义的WebSearchRetriever retriever = CustomWebSearchRetriever(search_url, headers) 构建执行链 Langchain需要构建一个执行链来进行指定工作，前面的文章中已经使用过本地向量数据库构建了一个执行链，本文是类似的，唯一的区别是提示词不同：\ndef search_and_generate(query): # 使用检索器搜索 template = \"\"\"你是一个帮助用户完成信息检索的智能助理，你的职责是根据提供的上下文回答用户的问题。 此外，你还需要遵守下列约定： 1、如果你不知道问题的答案，直接说不知道 上下文: {context} 我的问题是: {question} \"\"\" prompt = ChatPromptTemplate.from_template(template) rag_chain = ( {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm | StrOutputParser() ) # 开始查询\u0026生成 return rag_chain.invoke(query) 执行查询 最近几天出了高考分数线，我们问一下RAG：\n# 定义你想要搜索的问题 query = \"告诉我2024年的北京高考分数线\" # 执行搜索并生成回答 answer = search_and_generate(query) print(answer) 输出如下\nquerying 告诉我2024年的北京高考分数线 searched 9 results 2024年北京高考普通本科录取控制分数线为434分，特殊类型招生控制分数线为523分。同时，普通专科录取控制分数线为120分（语数外三科总分）。 这是在线检索得到的结果，完美！\n结论 通过结合互联网检索和LLM，我们可以显著提高RAG模型的时效性，使其能够提供最新的信息和内容。这种方法不仅适用于体育赛事报道，还可以扩展到其他需要实时数据的领域。随着技术的不断进步，我们可以期待更加智能和灵活的RAG模型，以满足不断变化的信息需求。\n本文代码如下：\nimport requests from bs4 import BeautifulSoup from langchain_openai import ChatOpenAI from langchain_core.output_parsers import StrOutputParser from langchain_core.prompts import ChatPromptTemplate from langchain_core.runnables import RunnablePassthrough, Runnable, RunnableConfig from langchain_core.runnables.utils import Input, Output from typing import Optional # 定义一个自定义的WebSearchRetriever class CustomWebSearchRetriever(Runnable): def __init__(self, search_url, headers=None): self.search_url = search_url self.headers = headers or {} def retrieve(self, query): # 保持之前的retrieve方法不变 response = requests.get(self.search_url, headers=self.headers, params={'wd': query}) soup = BeautifulSoup(response.text, 'html.parser') search_results = soup.find_all('div', class_='result') print(f\"searched {len(search_results)} results\") return '\\n'.join([result.get_text() for result in search_results]) def invoke(self, input: Input, config: Optional[RunnableConfig] = None) -\u003e Output: # invoke方法调用retrieve方法，并返回结果 print('querying', str(input)) return self.retrieve(input) # 初始化语言模型 # llm = OpenAI( # temperature=0, # api_key=\"sk-zgvGceDChpJjVedic1gFP0MFr8jpU4Oo0uNy0OM29dKRuqqz\", # base_url=\"https://api.moonshot.cn/v1/chat\", # model='moonshot-v1-8k', # ) llm = ChatOpenAI( model_name='moonshot-v1-8k', temperature=0.75, openai_api_base='https://api.moonshot.cn/v1', openai_api_key='sk-zgvGceDChpJjVedic1gFP0MFr8jpU4Oo0uNy0OM29dKRuqqz', streaming=False, ) # 配置搜索引擎的URL和headers search_url = \"https://www.baidu.com/s\" # 这里需要替换为实际的搜索引擎URL headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3' } # 初始化自定义的WebSearchRetriever retriever = CustomWebSearchRetriever(search_url, headers) # 定义一个函数来执行搜索并获取结果 def search_and_generate(query): # 使用检索器搜索 template = \"\"\"你是一个帮助用户完成信息检索的智能助理，你的职责是根据提供的上下文回答用户的问题。 此外，你还需要遵守下列约定： 1、如果你不知道问题的答案，直接说不知道 上下文: {context} 我的问题是: {question} \"\"\" prompt = ChatPromptTemplate.from_template(template) rag_chain = ( {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm | StrOutputParser() ) # 开始查询\u0026生成 return rag_chain.invoke(query) # 定义你想要搜索的问题 query = \"告诉我2024年的北京高考分数线\" # 执行搜索并生成回答 answer = search_and_generate(query) print(answer) ","wordCount":"378","inLanguage":"zh","datePublished":"2024-06-26T12:30:57+08:00","dateModified":"2024-06-26T12:30:57+08:00","author":{"@type":"Person","name":"Lei Xia"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.ddhigh.com/2024/06/26/rag-with-internet/"},"publisher":{"@type":"Organization","name":"每天进步一点点","logo":{"@type":"ImageObject","url":"https://www.ddhigh.com/favicon.ico"}}}</script><link rel=icon href=/img/favicon.ico sizes=16x16><link rel=apple-touch-icon href=/img/favicon.ico><link rel=manifest href=/img/favicon.ico><link href=https://fonts.cdnfonts.com/css/titillium-web rel=stylesheet><link rel=stylesheet href=/css/main.min.0eb4160ba4a2d63122fe8ae83f1560951a87ab510d5dab0615973b5206555759.css integrity="sha256-DrQWC6Si1jEi/oroPxVglRqHq1ENXasGFZc7UgZVV1k=" crossorigin=anonymous media=screen><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css integrity="sha512-ygEyjMC6rqnzJqWGjRTJUPYMEs9JUOm3i7OWUS9CgQ4XkBUvMsgCS1I8JqavidQ2ClHcREB7IbA2mN08+r9Elg==" crossorigin=anonymous referrerpolicy=no-referrer><link rel=stylesheet href=/scss/highlight/github-dark.min.min.66034289ee9a113219a2c4aae0a8bd2095ab255c832a42efcf5863f10814e7a1.css><script src=/js/highlight.min.min.c607d6febd16934a82eb61d3a896ed9d869f54373cc63ce95864ed5488fe3128.js></script><script>hljs.highlightAll()</script><script>$darkModeInit.Content|safeJS</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2871082647721658" crossorigin=anonymous></script></head><body><main class=wrapper><nav class=navigation><section class=container><a class=navigation-brand href=/>每天进步一点点
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><span></span><span></span><span></span></label><ul class=navigation-list id=navigation-list><li class="navigation-item navigation-menu"><a class=navigation-link href=/>首页</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/archives>归档</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/books>出版物</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/guestbook>留言板</a></li><li class="navigation-item menu-separator"><span>|</span></li><li class="navigation-item navigation-social"><a class=navigation-link href=https://github.com/xialeistudio><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></li><li class="navigation-item navigation-dark"><button id=mode type=button aria-label="toggle user light or dark theme">
<span class=toggle-dark><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span>
<span class=toggle-light><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button></li><li class="navigation-item navigation-language"><a href=https://www.ddhigh.com/en/>EN</a></li></ul></section></nav><div id=content><article class=blog-single><header class=blog-title><h1>利用互联网检索优化RAG模型的时效性问题</h1></header><p><small>2024年6月26日&nbsp;· 378 字&nbsp;· 2 分钟</small><p><div class=blog-toc><nav id=TableOfContents><ul><li><a href=#rag模型及其时效性挑战>RAG模型及其时效性挑战</a></li><li><a href=#基于搜索引擎的rag例子>基于搜索引擎的RAG例子</a><ul><li><a href=#安装组件>安装组件</a></li><li><a href=#构建检索器>构建检索器</a></li><li><a href=#初始化llm>初始化LLM</a></li><li><a href=#初始化检索器>初始化检索器</a></li><li><a href=#构建执行链>构建执行链</a></li><li><a href=#执行查询>执行查询</a></li></ul></li><li><a href=#结论>结论</a></li></ul></nav></div><section class=blog-content><p>在当今信息爆炸的时代，我们每天都在生成和消费海量的数据。对于依赖大量最新数据进行决策的领域，如金融分析、市场研究或实时新闻报道，传统的机器学习模型可能难以满足需求，因为它们通常在训练后便固定下来，难以适应快速变化的信息环境。近年来，Retrieval-Augmented Generation（RAG）模型因其结合了检索和生成的能力而受到关注。然而，RAG模型也面临着时效性问题。本文将探讨如何通过互联网检索和大型语言模型（LLM）来优化RAG模型的时效性。</p><h2 id=rag模型及其时效性挑战>RAG模型及其时效性挑战</h2><p>RAG模型通过将检索组件与生成组件相结合，提高了模型对特定查询的响应能力。然而，<strong>如果模型仅依赖于预先训练好的数据，它可能无法提供最新的信息</strong>。例如，在体育赛事中，比赛结束后，人们期望模型能够提供最新的比分和统计数据，而不是过时的信息。</p><p>为了解决时效性问题，我们可以利用互联网搜索引擎作为数据源。搜索引擎能够索引最新的网页内容，为我们提供实时更新的数据。通过编写特定的爬虫或使用API，我们可以从搜索引擎获取与查询相关的最新网页内容。</p><p>获取到最新的语料后，我们可以将其输入到大型语言模型中进行内容生成。LLM的强大之处在于它们能够理解和生成自然语言，这使得它们成为生成连贯、准确和相关文本的理想选择。</p><h2 id=基于搜索引擎的rag例子>基于搜索引擎的RAG例子</h2><p>接下来笔者将以一个基于百度搜索引擎以及月之暗面大模型的RAG例子进行逐步示范：</p><h3 id=安装组件>安装组件</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>pip install requests
</span></span><span style=display:flex><span>pip install bs4
</span></span><span style=display:flex><span>pip install langchain_openai
</span></span><span style=display:flex><span>pip install langchain_core
</span></span></code></pre></div><h3 id=构建检索器>构建检索器</h3><p>检索器需要继承<code>langchain_core.runnables.Runnable</code>并实现<code>invoke</code>方法，因此我们可以以任意数据源来构建检索器，而不仅仅是搜索引擎，下面是基于百度搜索引擎查询关键字并提取文本的代码：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>CustomWebSearchRetriever</span>(Runnable):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, search_url, headers<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>search_url <span style=color:#f92672>=</span> search_url
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>headers <span style=color:#f92672>=</span> headers <span style=color:#f92672>or</span> {}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>retrieve</span>(self, query):
</span></span><span style=display:flex><span>        response <span style=color:#f92672>=</span> requests<span style=color:#f92672>.</span>get(self<span style=color:#f92672>.</span>search_url, headers<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>headers, params<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#39;wd&#39;</span>: query})
</span></span><span style=display:flex><span>        soup <span style=color:#f92672>=</span> BeautifulSoup(response<span style=color:#f92672>.</span>text, <span style=color:#e6db74>&#39;html.parser&#39;</span>)
</span></span><span style=display:flex><span>        search_results <span style=color:#f92672>=</span> soup<span style=color:#f92672>.</span>find_all(<span style=color:#e6db74>&#39;div&#39;</span>, class_<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;result&#39;</span>)
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;searched </span><span style=color:#e6db74>{</span>len(search_results)<span style=color:#e6db74>}</span><span style=color:#e6db74> results&#34;</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#39;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>join([result<span style=color:#f92672>.</span>get_text() <span style=color:#66d9ef>for</span> result <span style=color:#f92672>in</span> search_results])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>invoke</span>(self, input: Input, config: Optional[RunnableConfig] <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>) <span style=color:#f92672>-&gt;</span> Output:
</span></span><span style=display:flex><span>        <span style=color:#75715e># invoke方法调用retrieve方法，并返回结果</span>
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#39;querying&#39;</span>, str(input))
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>retrieve(input)
</span></span></code></pre></div><h3 id=初始化llm>初始化LLM</h3><p>笔者使用的是<a href=https://platform.moonshot.cn/ target=_blank rel=noopener>月之暗面</a>，在前面的内容中我提到过Langchain提供了非常多的LLM，比如OpenAI的ChatGPT以及开源的llama3等。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>llm <span style=color:#f92672>=</span> ChatOpenAI(
</span></span><span style=display:flex><span>    model_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;moonshot-v1-8k&#39;</span>,
</span></span><span style=display:flex><span>    temperature<span style=color:#f92672>=</span><span style=color:#ae81ff>0.75</span>,
</span></span><span style=display:flex><span>    openai_api_base<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;https://api.moonshot.cn/v1&#39;</span>,
</span></span><span style=display:flex><span>    openai_api_key<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;秘钥&#39;</span>,
</span></span><span style=display:flex><span>    streaming<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>,
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><h3 id=初始化检索器>初始化检索器</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 配置搜索引擎的URL和headers</span>
</span></span><span style=display:flex><span>search_url <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;https://www.baidu.com/s&#34;</span>  <span style=color:#75715e># 这里需要替换为实际的搜索引擎URL</span>
</span></span><span style=display:flex><span>headers <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;User-Agent&#39;</span>: <span style=color:#e6db74>&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3&#39;</span>
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 初始化自定义的WebSearchRetriever</span>
</span></span><span style=display:flex><span>retriever <span style=color:#f92672>=</span> CustomWebSearchRetriever(search_url, headers)
</span></span></code></pre></div><h3 id=构建执行链>构建执行链</h3><p>Langchain需要构建一个执行链来进行指定工作，前面的文章中已经使用过本地向量数据库构建了一个执行链，本文是类似的，唯一的区别是提示词不同：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>search_and_generate</span>(query):
</span></span><span style=display:flex><span>    <span style=color:#75715e># 使用检索器搜索</span>
</span></span><span style=display:flex><span>    template <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;&#34;&#34;你是一个帮助用户完成信息检索的智能助理，你的职责是根据提供的上下文回答用户的问题。
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    此外，你还需要遵守下列约定：
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    1、如果你不知道问题的答案，直接说不知道
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    上下文: </span><span style=color:#e6db74>{context}</span><span style=color:#e6db74> 
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    我的问题是: </span><span style=color:#e6db74>{question}</span><span style=color:#e6db74> 
</span></span></span><span style=display:flex><span><span style=color:#e6db74>       &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    prompt <span style=color:#f92672>=</span> ChatPromptTemplate<span style=color:#f92672>.</span>from_template(template)
</span></span><span style=display:flex><span>    rag_chain <span style=color:#f92672>=</span> (
</span></span><span style=display:flex><span>            {<span style=color:#e6db74>&#34;context&#34;</span>: retriever, <span style=color:#e6db74>&#34;question&#34;</span>: RunnablePassthrough()}
</span></span><span style=display:flex><span>            <span style=color:#f92672>|</span> prompt
</span></span><span style=display:flex><span>            <span style=color:#f92672>|</span> llm
</span></span><span style=display:flex><span>            <span style=color:#f92672>|</span> StrOutputParser()
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    <span style=color:#75715e># 开始查询&amp;生成</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> rag_chain<span style=color:#f92672>.</span>invoke(query)
</span></span></code></pre></div><h3 id=执行查询>执行查询</h3><p>最近几天出了高考分数线，我们问一下RAG：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 定义你想要搜索的问题</span>
</span></span><span style=display:flex><span>query <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;告诉我2024年的北京高考分数线&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 执行搜索并生成回答</span>
</span></span><span style=display:flex><span>answer <span style=color:#f92672>=</span> search_and_generate(query)
</span></span><span style=display:flex><span>print(answer)
</span></span></code></pre></div><p>输出如下</p><pre tabindex=0><code>querying 告诉我2024年的北京高考分数线
searched 9 results
2024年北京高考普通本科录取控制分数线为434分，特殊类型招生控制分数线为523分。同时，普通专科录取控制分数线为120分（语数外三科总分）。
</code></pre><p>这是在线检索得到的结果，完美！</p><p><img alt=image-20240626154756206 src=https://raw.githubusercontent.com/xialeistudio/picture-bucket/main/blog/image-20240626154756206.png></p><h2 id=结论>结论</h2><p>通过结合互联网检索和LLM，我们可以显著提高RAG模型的时效性，使其能够提供最新的信息和内容。这种方法不仅适用于体育赛事报道，还可以扩展到其他需要实时数据的领域。随着技术的不断进步，我们可以期待更加智能和灵活的RAG模型，以满足不断变化的信息需求。</p><p>本文代码如下：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> requests
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> bs4 <span style=color:#f92672>import</span> BeautifulSoup
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain_openai <span style=color:#f92672>import</span> ChatOpenAI
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain_core.output_parsers <span style=color:#f92672>import</span> StrOutputParser
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain_core.prompts <span style=color:#f92672>import</span> ChatPromptTemplate
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain_core.runnables <span style=color:#f92672>import</span> RunnablePassthrough, Runnable, RunnableConfig
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain_core.runnables.utils <span style=color:#f92672>import</span> Input, Output
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> typing <span style=color:#f92672>import</span> Optional
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 定义一个自定义的WebSearchRetriever</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>CustomWebSearchRetriever</span>(Runnable):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, search_url, headers<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>search_url <span style=color:#f92672>=</span> search_url
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>headers <span style=color:#f92672>=</span> headers <span style=color:#f92672>or</span> {}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>retrieve</span>(self, query):
</span></span><span style=display:flex><span>        <span style=color:#75715e># 保持之前的retrieve方法不变</span>
</span></span><span style=display:flex><span>        response <span style=color:#f92672>=</span> requests<span style=color:#f92672>.</span>get(self<span style=color:#f92672>.</span>search_url, headers<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>headers, params<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#39;wd&#39;</span>: query})
</span></span><span style=display:flex><span>        soup <span style=color:#f92672>=</span> BeautifulSoup(response<span style=color:#f92672>.</span>text, <span style=color:#e6db74>&#39;html.parser&#39;</span>)
</span></span><span style=display:flex><span>        search_results <span style=color:#f92672>=</span> soup<span style=color:#f92672>.</span>find_all(<span style=color:#e6db74>&#39;div&#39;</span>, class_<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;result&#39;</span>)
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;searched </span><span style=color:#e6db74>{</span>len(search_results)<span style=color:#e6db74>}</span><span style=color:#e6db74> results&#34;</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#39;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>join([result<span style=color:#f92672>.</span>get_text() <span style=color:#66d9ef>for</span> result <span style=color:#f92672>in</span> search_results])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>invoke</span>(self, input: Input, config: Optional[RunnableConfig] <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>) <span style=color:#f92672>-&gt;</span> Output:
</span></span><span style=display:flex><span>        <span style=color:#75715e># invoke方法调用retrieve方法，并返回结果</span>
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#39;querying&#39;</span>, str(input))
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>retrieve(input)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 初始化语言模型</span>
</span></span><span style=display:flex><span><span style=color:#75715e># llm = OpenAI(</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#     temperature=0,</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#     api_key=&#34;sk-zgvGceDChpJjVedic1gFP0MFr8jpU4Oo0uNy0OM29dKRuqqz&#34;,</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#     base_url=&#34;https://api.moonshot.cn/v1/chat&#34;,</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#     model=&#39;moonshot-v1-8k&#39;,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># )</span>
</span></span><span style=display:flex><span>llm <span style=color:#f92672>=</span> ChatOpenAI(
</span></span><span style=display:flex><span>    model_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;moonshot-v1-8k&#39;</span>,
</span></span><span style=display:flex><span>    temperature<span style=color:#f92672>=</span><span style=color:#ae81ff>0.75</span>,
</span></span><span style=display:flex><span>    openai_api_base<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;https://api.moonshot.cn/v1&#39;</span>,
</span></span><span style=display:flex><span>    openai_api_key<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;sk-zgvGceDChpJjVedic1gFP0MFr8jpU4Oo0uNy0OM29dKRuqqz&#39;</span>,
</span></span><span style=display:flex><span>    streaming<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 配置搜索引擎的URL和headers</span>
</span></span><span style=display:flex><span>search_url <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;https://www.baidu.com/s&#34;</span>  <span style=color:#75715e># 这里需要替换为实际的搜索引擎URL</span>
</span></span><span style=display:flex><span>headers <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;User-Agent&#39;</span>: <span style=color:#e6db74>&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3&#39;</span>
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 初始化自定义的WebSearchRetriever</span>
</span></span><span style=display:flex><span>retriever <span style=color:#f92672>=</span> CustomWebSearchRetriever(search_url, headers)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 定义一个函数来执行搜索并获取结果</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>search_and_generate</span>(query):
</span></span><span style=display:flex><span>    <span style=color:#75715e># 使用检索器搜索</span>
</span></span><span style=display:flex><span>    template <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;&#34;&#34;你是一个帮助用户完成信息检索的智能助理，你的职责是根据提供的上下文回答用户的问题。
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    此外，你还需要遵守下列约定：
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    1、如果你不知道问题的答案，直接说不知道
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    上下文: </span><span style=color:#e6db74>{context}</span><span style=color:#e6db74> 
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    我的问题是: </span><span style=color:#e6db74>{question}</span><span style=color:#e6db74> 
</span></span></span><span style=display:flex><span><span style=color:#e6db74>       &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    prompt <span style=color:#f92672>=</span> ChatPromptTemplate<span style=color:#f92672>.</span>from_template(template)
</span></span><span style=display:flex><span>    rag_chain <span style=color:#f92672>=</span> (
</span></span><span style=display:flex><span>            {<span style=color:#e6db74>&#34;context&#34;</span>: retriever, <span style=color:#e6db74>&#34;question&#34;</span>: RunnablePassthrough()}
</span></span><span style=display:flex><span>            <span style=color:#f92672>|</span> prompt
</span></span><span style=display:flex><span>            <span style=color:#f92672>|</span> llm
</span></span><span style=display:flex><span>            <span style=color:#f92672>|</span> StrOutputParser()
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    <span style=color:#75715e># 开始查询&amp;生成</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> rag_chain<span style=color:#f92672>.</span>invoke(query)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 定义你想要搜索的问题</span>
</span></span><span style=display:flex><span>query <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;告诉我2024年的北京高考分数线&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 执行搜索并生成回答</span>
</span></span><span style=display:flex><span>answer <span style=color:#f92672>=</span> search_and_generate(query)
</span></span><span style=display:flex><span>print(answer)
</span></span></code></pre></div><div class=blog-footer><div class=social-share></div><div class=copyright><ul><li style=margin-bottom:.5em>本文作者: <a href=https://ddhigh.com/ target=_blank style=color:#000;text-decoration:none>xialeistudio</a></li><li style=margin-bottom:.5em>本文链接: <a href=https://www.ddhigh.com/2024/06/26/rag-with-internet/ target=_blank style=color:#000;text-decoration:none>利用互联网检索优化RAG模型的时效性问题</a></li><li>版权声明: <a href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank style=color:#000;text-decoration:none>「署名-非商业性使用-相同方式共享 4.0 国际」</a></li></ul></div><div style=margin-top:2rem><img src=/img/mp.png alt=qrcode></div></div></section><div class=paginator><a class=next href=https://www.ddhigh.com/2024/05/15/chatgpt4o-releaase/><span>重磅！ChatGPT团队官宣船新版本的多模态大模型GPT-4o，完全免费！</span><svg class="icon" width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M3.77086 21.1546C11.0491 22.698 21.4339 21.7773 21.4339 16.3608V4.63375c0-.69413-.075800000000001-1.3284-.2422-1.86588M3.77086 21.1546C1.9934 20.7777.973585 18.7264 1.08749 16.688c.17931-3.209.06972-7.25665-.08236-10.47293C.87809 3.52811 3.12891 1.16316 5.51029 1.25008c4.25565.15534 9.86671-.04779 13.28091-.24466 1.2952-.074686 2.0494.62843 2.4005 1.76245M3.77086 21.1546C4.56586 21.4723 5.49168 21.7879 6.5 22.0658M21.1917 2.76787c1.918 1.4143 1.9383 9.65123 1.7087 13.59293-2.0526 7.6586-10.5943 7.3054-16.4004 5.705M21.1917 2.76787C21.7612 4.51192 22.7203 9.67216 22 16.3608 21.2797 23.0494 11.3665 22.9511 6.5 22.0658M12.055 9C12.711 9.61644 14.3679 10.997 15.9519 11.7966 16.0174 11.8297 16.0154 11.9753 15.9494 12.0063 14.945 12.4779 13.0706 13.9264 12.055 15m3.5006-3.0333C13.1345 12.0608 8 12 6 11" stroke="currentcolor" stroke-linecap="round"/></svg></a></div><div class=comments><script>const getTheme=window.localStorage&&window.localStorage.getItem("theme");let theme=getTheme==="dark"?"dark":"light",s=document.createElement("script");s.src="https://giscus.app/client.js",s.setAttribute("data-repo","xialeistudio/discussion"),s.setAttribute("data-repo-id","R_kgDOKurTRA"),s.setAttribute("data-category","General"),s.setAttribute("data-category-id","DIC_kwDOKurTRM4CbCJt"),s.setAttribute("data-mapping","pathname"),s.setAttribute("data-strict","0"),s.setAttribute("data-reactions-enabled","1"),s.setAttribute("data-emit-metadata","0"),s.setAttribute("data-input-position","bottom"),s.setAttribute("data-theme",theme),s.setAttribute("data-lang","en"),s.setAttribute("data-loading","lazy"),s.setAttribute("crossorigin","anonymous"),s.setAttribute("async",""),document.querySelector("div.comments").innerHTML="",document.querySelector("div.comments").appendChild(s)</script></div></article></div><footer class=footer><p>&copy; 2014 - 2024 <a href=https://www.ddhigh.com/>每天进步一点点</a>
Powered by
<a href=https://gohugo.io/ rel=noopener target=_blank>Hugo️️</a>
<a href=https://github.com/guangzhengli/hugo-theme-ladder rel=noopener target=_blank>Ladder</a>
️</p></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M10.5376 22.7916C11.0152 22.7207 22.5795 21.1781 22.0978 10.4211 22.0536 9.43274 21.9303 8.53367 21.7387 7.71865M10.5376 22.7916C16.876 22.3728 20.0969 19.8899 21.5383 16.9142M10.5376 22.7916C9.7707 22.9055 8.97982 22.8964 8.19743 22.7725M21.7387 7.71865C21.4988 6.69828 21.1518 5.80967 20.7188 5.04257m1.0199 2.67608C22.6022 10.1105 23.0542 13.7848 21.5383 16.9142M20.7188 5.04257c-3.5504-6.28886-12.88753-4.410077-16.44303.0C2.88063 6.77451-.0433281 11.1668 1.38159 16.6571c.89322 3.4417 3.7911 5.6365 6.81584 6.1154M20.7188 5.04257c1.3509 1.89783 3.3111 6.34223 1.6353 10.37273M21.5383 16.9142C21.8737 16.4251 22.1428 15.9235 22.3541 15.4153M8.19743 22.7725C12.1971 23.4683 20.6281 22.971 22.3541 15.4153M14 10.945C13.3836 10.289 12.003 8.63215 11.2034 7.04814 11.1703 6.98257 11.0247 6.98456 10.9937 7.05061 10.5221 8.05496 9.07362 9.92941 8 10.945m3.0333-3.50056C10.9392 9.86549 11 15 12 17" stroke="currentcolor" stroke-linecap="round"/></svg>
</a><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const s=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="Copy";function n(){t.innerHTML="Copied",setTimeout(()=>{t.innerHTML="Copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),n();return}const s=document.createRange();s.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(s);try{document.execCommand("copy"),n()}catch{}o.removeRange(s)}),e.parentNode.appendChild(t)})</script><script src=https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js integrity="sha512-9DNXrSjk17bU9MUbRp3IjwcWe46V8FaGA062PFbryPUAEQVRbz4jiZP6FW0AdbqEGtMYBDWnul3eiGBMJOQajA==" crossorigin=anonymous referrerpolicy=no-referrer></script></main></body><script src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin=anonymous referrerpolicy=no-referrer></script><script>const images=Array.from(document.querySelectorAll(".blog-content img"));images.forEach(e=>{mediumZoom(e,{margin:10,scrollOffset:40,container:null,template:null,background:"rgba(0, 0, 0, 0.5)"})})</script><script src=/main.min.6bb26b69159420159c74dc9e097b06a578ed2b68c701466a91a44a9632d851bd0af167a1b30012387b4c512b48ad9ad4d3394e04d77ae38d57e1920fe4ed34fe.js integrity="sha512-a7JraRWUIBWcdNyeCXsGpXjtK2jHAUZqkaRKljLYUb0K8WehswASOHtMUStIrZrU0zlOBNd6441X4ZIP5O00/g==" crossorigin=anonymous defer></script></html>
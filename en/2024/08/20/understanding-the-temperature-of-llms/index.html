<!doctype html><html lang=en><head><meta name=viewport content="width=device-width,initial-scale=1"><title>Understanding the "Temperature" of Large Language Models</title>
<meta charset=utf-8><meta name=google-adsense-account content="ca-pub-2871082647721658"><meta content="Web ,Java ,Go ,Node.js ,PHP ,Koa ,MySQL ,Redis ,front-end ,back-end ,database" name=keywords><meta name=description content="In the realm of artificial intelligence, large language models (LLMs) have become sophisticated tools for generating human-like text. A pivotal concept in steering these models is the &ldquo;temperature,&rdquo; which dictates the randomness and creativity of the generated text. This blog post aims to demystify the temperature setting in LLMs and provide a professional overview."><meta name=author content="Lei Xia"><link rel=canonical href=https://www.ddhigh.com/en/2024/08/20/understanding-the-temperature-of-llms/><link rel=alternate type=application/rss+xml href=https://www.ddhigh.com/index.xml title=每天进步一点点><script async defer data-website-id=52f8f0f9-d93d-466b-8ef5-508aae8c4ed4 src=https://analysis.ddhigh.com/script.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-EC3XLVSGKV"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-EC3XLVSGKV")</script><meta property="og:title" content="Understanding the &#34;Temperature&#34; of Large Language Models"><meta property="og:description" content="In the realm of artificial intelligence, large language models (LLMs) have become sophisticated tools for generating human-like text. A pivotal concept in steering these models is the &ldquo;temperature,&rdquo; which dictates the randomness and creativity of the generated text. This blog post aims to demystify the temperature setting in LLMs and provide a professional overview."><meta property="og:type" content="article"><meta property="og:url" content="https://www.ddhigh.com/en/2024/08/20/understanding-the-temperature-of-llms/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-08-20T15:57:11+08:00"><meta property="article:modified_time" content="2024-08-20T15:57:11+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Understanding the &#34;Temperature&#34; of Large Language Models"><meta name=twitter:description content="In the realm of artificial intelligence, large language models (LLMs) have become sophisticated tools for generating human-like text. A pivotal concept in steering these models is the &ldquo;temperature,&rdquo; which dictates the randomness and creativity of the generated text. This blog post aims to demystify the temperature setting in LLMs and provide a professional overview."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":4,"name":"Understanding the \"Temperature\" of Large Language Models","item":"https://www.ddhigh.com/en/2024/08/20/understanding-the-temperature-of-llms/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Understanding the \"Temperature\" of Large Language Models","name":"Understanding the \u0022Temperature\u0022 of Large Language Models","description":"In the realm of artificial intelligence, large language models (LLMs) have become sophisticated tools for generating human-like text. A pivotal concept in steering these models is the \u0026ldquo;temperature,\u0026rdquo; which dictates the randomness and creativity of the generated text. This blog post aims to demystify the temperature setting in LLMs and provide a professional overview.\n","keywords":[],"articleBody":"In the realm of artificial intelligence, large language models (LLMs) have become sophisticated tools for generating human-like text. A pivotal concept in steering these models is the “temperature,” which dictates the randomness and creativity of the generated text. This blog post aims to demystify the temperature setting in LLMs and provide a professional overview.\nWhat is a Large Language Model? LLMs are AI systems trained on extensive text data, enabling them to comprehend and produce language akin to human speech. They are adept at various language tasks, including translation, summarization, and content creation.\nThe Role of Temperature Temperature is a hyperparameter that governs the randomness in the probability distribution function of LLMs when generating text. It influences the output as follows:\nHigh Temperature: Increases randomness, fostering more diverse and creative outputs but potentially leading to incoherence or irrelevance. Low Temperature: Decreases randomness, yielding more predictable and focused outputs, which might be consistent but less imaginative. How Temperature Works During text generation, an LLM predicts the next word based on the context of preceding words. The model assigns probabilities to each possible subsequent word. The temperature setting modifies these probabilities:\nAt a high temperature, the model is more inclined to pick less probable words, resulting in a wider range of responses. At a low temperature, the model gravitates toward the most probable words, favoring common and expected responses. Practical Applications Adjusting the temperature is crucial for tailoring the LLM’s performance to specific tasks:\nCreative Writing: A higher temperature could encourage creativity and uniqueness in text generation. Technical Writing: A lower temperature might ensure precision and consistency in technical documentation. Balancing Act Achieving the optimal temperature involves a delicate balance. It requires experimentation and an appreciation of the trade-offs between creativity and coherence. The objective is to find a setting that meets the quality and use-case requirements.\nExample of Temperature in Action Imagine you’re using a large language model (LLM) to continue the sentence: “The early bird catches the…”\nProbabilities at Different Temperatures: High Temperature (e.g., 1.5):\n“worm”: 10% “morning”: 15% “sunrise”: 20% “opportunity”: 25% “moment”: 10% “evening star”: 20% At a high temperature, the LLM might select a less common continuation, generating a sentence like: “The early bird catches the evening star, a celestial event that marks the start of a new day.”\nMedium Temperature (e.g., 1.0, default):\n“worm”: 30% “morning”: 20% “sunrise”: 15% “opportunity”: 20% “moment”: 10% “evening star”: 5% With the default temperature, the LLM is more likely to choose a probable word, resulting in a sentence like: “The early bird catches the morning, ensuring a productive start to the day.”\nLow Temperature (e.g., 0.5):\n“worm”: 70% “morning”: 10% “sunrise”: 5% “opportunity”: 10% “moment”: 2% “evening star”: 3% At a low temperature, the LLM will favor the most probable word, leading to a predictable sentence: “The early bird catches the worm, a common saying that emphasizes the value of starting the day early.”\nConclusion In summary, the temperature of a large language model is an essential control for managing the randomness and creativity of AI-generated text. By grasping and adjusting this parameter, users can fully leverage the capabilities of LLMs for diverse applications. As with any tool, success lies in knowing how and when to apply it effectively.\n","wordCount":"539","inLanguage":"en","datePublished":"2024-08-20T15:57:11+08:00","dateModified":"2024-08-20T15:57:11+08:00","author":{"@type":"Person","name":"Lei Xia"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.ddhigh.com/en/2024/08/20/understanding-the-temperature-of-llms/"},"publisher":{"@type":"Organization","name":"每天进步一点点","logo":{"@type":"ImageObject","url":"https://www.ddhigh.com/favicon.ico"}}}</script><link rel=icon href=/img/favicon.ico sizes=16x16><link rel=apple-touch-icon href=/img/favicon.ico><link rel=manifest href=/img/favicon.ico><link href=/titilliumweb/titilliumweb.css rel=stylesheet><link rel=stylesheet href=/css/main.min.0eb4160ba4a2d63122fe8ae83f1560951a87ab510d5dab0615973b5206555759.css integrity="sha256-DrQWC6Si1jEi/oroPxVglRqHq1ENXasGFZc7UgZVV1k=" crossorigin=anonymous media=screen><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css integrity="sha512-ygEyjMC6rqnzJqWGjRTJUPYMEs9JUOm3i7OWUS9CgQ4XkBUvMsgCS1I8JqavidQ2ClHcREB7IbA2mN08+r9Elg==" crossorigin=anonymous referrerpolicy=no-referrer><link rel=stylesheet href=/scss/highlight/github-dark.min.min.66034289ee9a113219a2c4aae0a8bd2095ab255c832a42efcf5863f10814e7a1.css><script src=/js/highlight.min.min.894ca9c68afab956438c4926a0dc7f5293e04e08595bd27abdb123e94801f684.js></script><script>hljs.highlightAll()</script><script>$darkModeInit.Content|safeJS</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2871082647721658" crossorigin=anonymous></script></head><body><main class=wrapper><nav class=navigation><section class=container><a class=navigation-brand href=/en>DayDayUP
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><span></span><span></span><span></span></label><ul class=navigation-list id=navigation-list><li class="navigation-item navigation-menu"><a class=navigation-link href=/en/>Home</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/en/archives>Archives</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/en/books>Books</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/en/guestbook>Guestbook</a></li><li class="navigation-item menu-separator"><span>|</span></li><li class="navigation-item navigation-social"><a class=navigation-link href=https://github.com/xialeistudio><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></li><li class="navigation-item navigation-dark"><button id=mode type=button aria-label="toggle user light or dark theme">
<span class=toggle-dark><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span><span class=toggle-light><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button></li><li class="navigation-item navigation-language"><a href=https://www.ddhigh.com/2024/08/20/understanding-the-temperature-of-llms/>中</a></li></ul></section></nav><div id=content><article class=blog-single><header class=blog-title><h1>Understanding the "Temperature" of Large Language Models</h1></header><p><small>August 20, 2024&nbsp;· 539 words&nbsp;· 3 min</small><p><div class=blog-toc><nav id=TableOfContents><ul><li><a href=#what-is-a-large-language-model>What is a Large Language Model?</a></li><li><a href=#the-role-of-temperature>The Role of Temperature</a></li><li><a href=#how-temperature-works>How Temperature Works</a></li><li><a href=#practical-applications>Practical Applications</a></li><li><a href=#balancing-act>Balancing Act</a></li><li><a href=#example-of-temperature-in-action>Example of Temperature in Action</a><ul><li><a href=#probabilities-at-different-temperatures>Probabilities at Different Temperatures:</a></li><li><a href=#conclusion>Conclusion</a></li></ul></li></ul></nav></div><section class=blog-content><p>In the realm of artificial intelligence, large language models (LLMs) have become sophisticated tools for generating human-like text. A pivotal concept in steering these models is the &ldquo;temperature,&rdquo; which dictates the randomness and creativity of the generated text. This blog post aims to demystify the temperature setting in LLMs and provide a professional overview.</p><h2 id=what-is-a-large-language-model>What is a Large Language Model?</h2><p>LLMs are AI systems trained on extensive text data, enabling them to comprehend and produce language akin to human speech. They are adept at various language tasks, including translation, summarization, and content creation.</p><h2 id=the-role-of-temperature>The Role of Temperature</h2><p>Temperature is a hyperparameter that governs the randomness in the probability distribution function of LLMs when generating text. It influences the output as follows:</p><ul><li><strong>High Temperature</strong>: Increases randomness, fostering more diverse and creative outputs but potentially leading to incoherence or irrelevance.</li><li><strong>Low Temperature</strong>: Decreases randomness, yielding more predictable and focused outputs, which might be consistent but less imaginative.</li></ul><h2 id=how-temperature-works>How Temperature Works</h2><p>During text generation, an LLM predicts the next word based on the context of preceding words. The model assigns probabilities to each possible subsequent word. The temperature setting modifies these probabilities:</p><ul><li>At a <strong>high temperature</strong>, the model is more inclined to pick less probable words, resulting in a wider range of responses.</li><li>At a <strong>low temperature</strong>, the model gravitates toward the most probable words, favoring common and expected responses.</li></ul><h2 id=practical-applications>Practical Applications</h2><p>Adjusting the temperature is crucial for tailoring the LLM&rsquo;s performance to specific tasks:</p><ul><li><strong>Creative Writing</strong>: A higher temperature could encourage creativity and uniqueness in text generation.</li><li><strong>Technical Writing</strong>: A lower temperature might ensure precision and consistency in technical documentation.</li></ul><h2 id=balancing-act>Balancing Act</h2><p>Achieving the optimal temperature involves a delicate balance. It requires experimentation and an appreciation of the trade-offs between creativity and coherence. The objective is to find a setting that meets the quality and use-case requirements.</p><h2 id=example-of-temperature-in-action>Example of Temperature in Action</h2><p>Imagine you&rsquo;re using a large language model (LLM) to continue the sentence: &ldquo;The early bird catches the&mldr;&rdquo;</p><h3 id=probabilities-at-different-temperatures>Probabilities at Different Temperatures:</h3><ul><li><p><strong>High Temperature (e.g., 1.5)</strong>:</p><ul><li>&ldquo;worm&rdquo;: 10%</li><li>&ldquo;morning&rdquo;: 15%</li><li>&ldquo;sunrise&rdquo;: 20%</li><li>&ldquo;opportunity&rdquo;: 25%</li><li>&ldquo;moment&rdquo;: 10%</li><li>&ldquo;evening star&rdquo;: 20%</li></ul><p>At a high temperature, the LLM might select a less common continuation, generating a sentence like: &ldquo;The early bird catches the evening star, a celestial event that marks the start of a new day.&rdquo;</p></li><li><p><strong>Medium Temperature (e.g., 1.0, default)</strong>:</p><ul><li>&ldquo;worm&rdquo;: 30%</li><li>&ldquo;morning&rdquo;: 20%</li><li>&ldquo;sunrise&rdquo;: 15%</li><li>&ldquo;opportunity&rdquo;: 20%</li><li>&ldquo;moment&rdquo;: 10%</li><li>&ldquo;evening star&rdquo;: 5%</li></ul><p>With the default temperature, the LLM is more likely to choose a probable word, resulting in a sentence like: &ldquo;The early bird catches the morning, ensuring a productive start to the day.&rdquo;</p></li><li><p><strong>Low Temperature (e.g., 0.5)</strong>:</p><ul><li>&ldquo;worm&rdquo;: 70%</li><li>&ldquo;morning&rdquo;: 10%</li><li>&ldquo;sunrise&rdquo;: 5%</li><li>&ldquo;opportunity&rdquo;: 10%</li><li>&ldquo;moment&rdquo;: 2%</li><li>&ldquo;evening star&rdquo;: 3%</li></ul><p>At a low temperature, the LLM will favor the most probable word, leading to a predictable sentence: &ldquo;The early bird catches the worm, a common saying that emphasizes the value of starting the day early.&rdquo;</p></li></ul><h3 id=conclusion>Conclusion</h3><p>In summary, the temperature of a large language model is an essential control for managing the randomness and creativity of AI-generated text. By grasping and adjusting this parameter, users can fully leverage the capabilities of LLMs for diverse applications. As with any tool, success lies in knowing how and when to apply it effectively.</p><div class=blog-footer><div class=social-share></div><div class=copyright><ul><li style=margin-bottom:.5em>Author: <a href=https://ddhigh.com/ target=_blank style=color:#000;text-decoration:none>xialeistudio</a></li><li style=margin-bottom:.5em>Link: <a href=https://www.ddhigh.com/en/2024/08/20/understanding-the-temperature-of-llms/ target=_blank style=color:#000;text-decoration:none>Understanding the "Temperature" of Large Language Models</a></li><li>Copyright: <a href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank style=color:#000;text-decoration:none>「CC BY-NC 4.0 DEED」</a></li></ul></div></div></section><div class=paginator><a class=prev href=https://www.ddhigh.com/en/2024/08/22/build-a-weather-query-agent/><svg class="icon" width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.77086 21.1546C11.0491 22.698 21.4339 21.7773 21.4339 16.3608V4.63375c0-.69413-.075800000000001-1.3284-.2422-1.86588M3.77086 21.1546C1.9934 20.7777.973585 18.7264 1.08749 16.688c.17931-3.209.06972-7.25665-.08236-10.47293C.87809 3.52811 3.12891 1.16316 5.51029 1.25008c4.25565.15534 9.86671-.04779 13.28091-.24466 1.2952-.074686 2.0494.62843 2.4005 1.76245M3.77086 21.1546C4.56586 21.4723 5.49168 21.7879 6.5 22.0658M21.1917 2.76787c1.918 1.4143 1.9383 9.65123 1.7087 13.59293-2.0526 7.6586-10.5943 7.3054-16.4004 5.705M21.1917 2.76787C21.7612 4.51192 22.7203 9.67216 22 16.3608 21.2797 23.0494 11.3665 22.9511 6.5 22.0658M9.94496 9C9.28897 9.61644 7.63215 10.997 6.04814 11.7966 5.98257 11.8297 5.98456 11.9753 6.05061 12.0063c1.00435.4716 2.8788 1.9201 3.89435 2.9937M6.44444 11.9667C8.86549 12.0608 14 12 16 11" stroke="currentcolor" stroke-linecap="round"/></svg><span>Build a weather query agent</span></a>
<a class=next href=https://www.ddhigh.com/en/2024/08/15/build-your-ai-search-bot-with-llm-and-search-engines/><span>Build Your AI Search Bot with LLM and Search Engines</span><svg class="icon" width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M3.77086 21.1546C11.0491 22.698 21.4339 21.7773 21.4339 16.3608V4.63375c0-.69413-.075800000000001-1.3284-.2422-1.86588M3.77086 21.1546C1.9934 20.7777.973585 18.7264 1.08749 16.688c.17931-3.209.06972-7.25665-.08236-10.47293C.87809 3.52811 3.12891 1.16316 5.51029 1.25008c4.25565.15534 9.86671-.04779 13.28091-.24466 1.2952-.074686 2.0494.62843 2.4005 1.76245M3.77086 21.1546C4.56586 21.4723 5.49168 21.7879 6.5 22.0658M21.1917 2.76787c1.918 1.4143 1.9383 9.65123 1.7087 13.59293-2.0526 7.6586-10.5943 7.3054-16.4004 5.705M21.1917 2.76787C21.7612 4.51192 22.7203 9.67216 22 16.3608 21.2797 23.0494 11.3665 22.9511 6.5 22.0658M12.055 9C12.711 9.61644 14.3679 10.997 15.9519 11.7966 16.0174 11.8297 16.0154 11.9753 15.9494 12.0063 14.945 12.4779 13.0706 13.9264 12.055 15m3.5006-3.0333C13.1345 12.0608 8 12 6 11" stroke="currentcolor" stroke-linecap="round"/></svg></a></div><div class=comments><script>const getTheme=window.localStorage&&window.localStorage.getItem("theme");let theme=getTheme==="dark"?"dark":"light",s=document.createElement("script");s.src="https://giscus.app/client.js",s.setAttribute("data-repo","xialeistudio/discussion"),s.setAttribute("data-repo-id","R_kgDOKurTRA"),s.setAttribute("data-category","General"),s.setAttribute("data-category-id","DIC_kwDOKurTRM4CbCJt"),s.setAttribute("data-mapping","pathname"),s.setAttribute("data-strict","0"),s.setAttribute("data-reactions-enabled","1"),s.setAttribute("data-emit-metadata","0"),s.setAttribute("data-input-position","bottom"),s.setAttribute("data-theme",theme),s.setAttribute("data-lang","en"),s.setAttribute("data-loading","lazy"),s.setAttribute("crossorigin","anonymous"),s.setAttribute("async",""),document.querySelector("div.comments").innerHTML="",document.querySelector("div.comments").appendChild(s)</script></div></article></div><footer class=footer><p>&copy; 2014 - 2024 <a href=https://www.ddhigh.com>每天进步一点点</a>
Powered by
<a href=https://gohugo.io/ rel=noopener target=_blank>Hugo️️</a>
<a href=https://github.com/guangzhengli/hugo-theme-ladder rel=noopener target=_blank>Ladder</a>
️</p></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.5376 22.7916C11.0152 22.7207 22.5795 21.1781 22.0978 10.4211 22.0536 9.43274 21.9303 8.53367 21.7387 7.71865M10.5376 22.7916C16.876 22.3728 20.0969 19.8899 21.5383 16.9142M10.5376 22.7916C9.7707 22.9055 8.97982 22.8964 8.19743 22.7725M21.7387 7.71865C21.4988 6.69828 21.1518 5.80967 20.7188 5.04257m1.0199 2.67608C22.6022 10.1105 23.0542 13.7848 21.5383 16.9142M20.7188 5.04257c-3.5504-6.28886-12.88753-4.410077-16.44303.0C2.88063 6.77451-.0433281 11.1668 1.38159 16.6571c.89322 3.4417 3.7911 5.6365 6.81584 6.1154M20.7188 5.04257c1.3509 1.89783 3.3111 6.34223 1.6353 10.37273M21.5383 16.9142C21.8737 16.4251 22.1428 15.9235 22.3541 15.4153M8.19743 22.7725C12.1971 23.4683 20.6281 22.971 22.3541 15.4153M14 10.945C13.3836 10.289 12.003 8.63215 11.2034 7.04814 11.1703 6.98257 11.0247 6.98456 10.9937 7.05061 10.5221 8.05496 9.07362 9.92941 8 10.945m3.0333-3.50056C10.9392 9.86549 11 15 12 17" stroke="currentcolor" stroke-linecap="round"/></svg></a><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const s=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="Copy";function n(){t.innerHTML="Copied",setTimeout(()=>{t.innerHTML="Copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),n();return}const s=document.createRange();s.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(s);try{document.execCommand("copy"),n()}catch{}o.removeRange(s)}),e.parentNode.appendChild(t)})</script><script src=https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js integrity="sha512-9DNXrSjk17bU9MUbRp3IjwcWe46V8FaGA062PFbryPUAEQVRbz4jiZP6FW0AdbqEGtMYBDWnul3eiGBMJOQajA==" crossorigin=anonymous referrerpolicy=no-referrer></script></main></body><script src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin=anonymous referrerpolicy=no-referrer></script><script>const images=Array.from(document.querySelectorAll(".blog-content img"));images.forEach(e=>{mediumZoom(e,{margin:10,scrollOffset:40,container:null,template:null,background:"rgba(0, 0, 0, 0.5)"})})</script><script src=/main.min.6bb26b69159420159c74dc9e097b06a578ed2b68c701466a91a44a9632d851bd0af167a1b30012387b4c512b48ad9ad4d3394e04d77ae38d57e1920fe4ed34fe.js integrity="sha512-a7JraRWUIBWcdNyeCXsGpXjtK2jHAUZqkaRKljLYUb0K8WehswASOHtMUStIrZrU0zlOBNd6441X4ZIP5O00/g==" crossorigin=anonymous defer></script></html>